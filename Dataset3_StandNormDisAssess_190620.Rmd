---
title: "Normalization and beta-diversity index"
author: "Casper Sahl Poulsen"
date: '09072019'
always_allow_html: yes
output:
  pdf_document:
    toc: yes
    toc_depth: '5'
  html_document:
    toc: yes
    toc_depth: 5
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE, 
                      message = FALSE,
                      fig.align = "center")
```

## Introduction
The purpose of the following code is to assess the effect of normalization and calculation of beta-diversity to analyze compositional ecology data. This is typical for metagenomics or 16S data used for taxonomic characterisation of microbial communities.  

### Assumptions
The framework were applied to an example dataset provided in the "microbiome" bioconductor R package. The study investigates the association between diet and colon cancer in African Americans and rural Africans. A subset of the samples were included using the following criteria. Samples were part of the home environment (HE) study and only using the samples obtained from African Americans.  
The testdata contains two groups where it is expected to see differences between the two groups, but relatively smaller effects compared with comparing the microbiome of African Americans and rural Africans.

### To change testdata  
Testdata needs to be provided with rownames as features and colnames as samples.  
Metadata needs to be provided with columns representing the metadata.  
Have to change shape and color specifications according to user preferances as well as in the ggplot call of PCoAs.
  
### To add new normalization or beta-diversity metrics  
The code is currently setup to run with a selected number of combinations of normalization and beta-diversity metric. A already defined combination can be added to the rows vector to generate the heatmap and the dissimilarity/distance list (DistList or DistList2) to generate the PCoA.
To add a new combination create dissimilarity/distance matrix add it to the DistList and the dissimilarity/distance relative to the reference to the rows vector. Update color and shape schemes accordingly. 
  
### To change heatmap clustering and PCoA algorithm  
The heatmap clustering can be changed using the function parameters "clustering_distance_cols" and "clustering_distance_rows". vegan::capscale were run unconstrained to create PCoA other PCoA algorithms can be used, we recommend reading about these here: http://cc.oulu.fi/~jarioksa/opetus/metodi/vegantutor.pdf and Buttigieg PL, Ramette A (2014) A Guide to Statistical Analysis in Microbial Ecology: a community-focused, living review of multivariate data analyses. FEMS Microbiol Ecol. 90: 543-550. Other vegan functions can be changed directly, but does not always have implementations for stress plots and scree plots.  
  
### Disclaimer    
It is important to be aware that the pipelines does not provide a single solution to a multifactorial problem and the appropriate decision regarding the applicabilty of a pipeline is inherently depending on the data at hand. 
  
### Packages 
```{r}
#install.packages("installr")
#library(installr)
#updateR()
#version

#Run to install all packages. Bioconductor packages are installed seperately below
#install.packages(c("vegan", "rlang", "Rcpp", "tidyselect", "dplyr", "knitr", "ggplot2",
#                   "pheatmap", "zCompositions", "compositions", "reshape", "tidyr", 
#                   "gridExtra", "cowplot", "stringi", "ggthemes", "scales", 
#                   "RColorBrewer", "plotly", "ape"))
library(vegan) 
library(rlang)
library(Rcpp)
library(tidyselect)
library(dplyr) 
library(knitr) 
library(scales)
library(ggplot2)
library(pheatmap) 
library(zCompositions)
library(compositions)
library(reshape)
library(tidyr)
library(gridExtra)
library(cowplot)
library(stringi)
library(ggthemes)  
library(RColorBrewer)
library(digest)
library(plotly)

#if (!requireNamespace("BiocManager", quietly = TRUE))
#    install.packages("BiocManager")
#BiocManager::install("metagenomeSeq") 
library(metagenomeSeq)

#if (!requireNamespace("BiocManager", quietly = TRUE))
#    install.packages("BiocManager")
#BiocManager::install("BiocGenerics")
#if (!requireNamespace("BiocManager", quietly = TRUE))
#    install.packages("BiocManager")
#BiocManager::install("DelayedArray")
#if (!requireNamespace("BiocManager", quietly = TRUE))
#    install.packages("BiocManager")
#BiocManager::install("DESeq2")
library(DESeq2)
#if (!requireNamespace("BiocManager", quietly = TRUE))
#    install.packages("BiocManager")
#BiocManager::install("edgeR")
library(edgeR)
#if (!requireNamespace("BiocManager", quietly = TRUE))
#    install.packages("BiocManager")
#BiocManager::install("ggtree")
library(ggtree)
#if (!requireNamespace("BiocManager", quietly = TRUE))
#    install.packages("BiocManager")
#BiocManager::install("microbiome")
library(microbiome)

#install.packages("harrietr")
library(harrietr)
library(ape)
library(stringr)
```

## Analysis
### Create count table (Testdata) and metadata (Metadata)
```{r}
data(dietswap)

#Create Metadata only include samples from HE study and at the first time point
Metadata <- data.frame(dietswap@sam_data@.Data)
colnames(Metadata) <- dietswap@sam_data@names
Metadata<-filter(Metadata, group == "HE" & nationality == "AAM")
#table(Metadata$timepoint.within.group)
Metadata$sample <- gsub("-", ".", Metadata$sample) 
#Change to character
Metadata$timepoint.within.group <- as.character(Metadata$timepoint.within.group)

#Create testdata 
Testdata <- data.frame(dietswap@otu_table@.Data) #dim(Testdata) #222 samples and 130 features
#Subset according to selected samples
Testdata<-select(Testdata, one_of(Metadata$sample))

#Remove features if they are not present in the subset of samples 
Testdata <- Testdata[rowSums(Testdata)>0,] #42 samples and 118 features have to update

rm(dietswap)
```

## Define Color and shape scheme
```{r}
#Define coloring schemes
#To create PCoA/PCA
TestCol<-c("1" = "#377EB8", "2" = "#E41A1C") 
#To create procrustes PCoA/PCA
ProCCol<-c("chisq" = "#E41A1C", "freq" = "#4DAF4A", "max" = "#FFFF33", 
           "norm" = "#A65628", "clr"="#E41A1C", "ilr"="#9f1214", "CSS"="#ed5e5f", 
           "DESeq"="#377EB8", "TMM"="#265880", "hellinger"="#4DAF4A", 
           "TSS_hellinger"="#357933", "log"="#984EA3", "TSS_log"="#5b2e61", 
           "pa"="#FF7F00", "Rarefy"="#FFFF33", "TSS"="#A65628") 
           
##Define shape schemes
#table(Metadata$Level)
#To create PCoA/PCA
LevelShape<-c("lean"=1, "overweight"=0, "obese"=2) 
#To create procrustes PCoA/PCA 
ProCShape<-c("altGower"=9, "binomial"=5, "bray"=3, "canberra"=6, "euclidean"=0, 
             "gower"=8, "horn"=2, "jaccard"=1, "kulczynski"=7, "manhattan"=4) 
#To create procrustes PCoA/PCA
annotation_colorsHeat = list(betadiversity = c(bray = "#E41A1C", euclidean= "#377EB8", 
                                               manhattan="#4DAF4A"), 
                             Preprocessing = c(clr="#E41A1C", ilr="#9f1214", 
                                               CSS="#ed5e5f", DESeq="#377EB8", 
                                               TMM="#265880", hellinger="#4DAF4A", 
                                               hellingerTSS="#357933", log="#984EA3", 
                                               logTSS="#5b2e61", pa="#FF7F00", 
                                               Rar="#FFFF33", TSS="#A65628")) 
```


### Normalization and beta-diversity indices compared
Creating list of all dissimilarity/distance objects (DistList) 
Creating df with dissimilarities/distances relative to the reference using real values (df) and ranks (dfrank)  
The same calculations were made subsetting only to exact modifications of the ref, both as real values and ranks 
```{r}
df2<-data.frame()
DistList2 <- list()
for (i in c("manhattan", "euclidean", "canberra", "bray", "kulczynski", "jaccard", 
            "gower", "altGower", "horn", "binomial")) {
  for (j in c("total", "max", "freq", "normalize", "pa", "hellinger", "log")) {
    distmatrix<-vegdist(decostand(decostand(t(Testdata), method="total"), method=j), 
                        method=i)
    #Create list containing the dist matrices
    distName <- paste( 'dist', i, j, sep = '' )
    DistList2[[ distName ]]<-distmatrix
    #Make distances into matrix
    distmatrix <- data.frame(as.matrix(distmatrix))
    deco<-j
    dissi<-i
    df2<-rbind(df2, data.frame(deco, dissi, 
                               data.frame(distmatrix[1,2:length(distmatrix)])))
  }
}


#If TSS is performed after other transformations/standardizations/normalizations
for (i in c("manhattan", "euclidean", "canberra", "bray", "kulczynski", "jaccard", 
            "gower", "altGower", "horn", "binomial")) {
  for (j in c("total", "max", "freq", "normalize", "pa", "hellinger", "log")) {
    distmatrix<-vegdist(decostand(decostand(t(Testdata), method=j), method="total"), 
                        method=i)
    #Create list containing the dist matrices
    distName <- paste( 'dist', i, "total", j, sep = '' )
    DistList2[[ distName ]]<-distmatrix
    #Make distances into matrix
    distmatrix <- data.frame(as.matrix(distmatrix))
    deco<-paste(j, "TSS", sep="")
    dissi<-i
    df2<-rbind(df2, data.frame(deco, dissi, 
                               data.frame(distmatrix[1,2:length(distmatrix)])))
  }
}

##Rarefying using the rrarefy function from vegan
dataRar <- t(rrarefy(t(Testdata), min(colSums(Testdata))))
j <- "Rar"
for (i in c("manhattan", "euclidean", "canberra", "bray", "kulczynski", "jaccard", 
            "gower", "altGower", "horn", "binomial")) {
  distmatrix<-vegdist(t(dataRar), method=i)
  #Create list containing the dist matrices
  distName <- paste( 'dist', i, j, sep = '' )
  DistList2[[ distName ]]<-distmatrix
  #Make distances into matrix
  distmatrix <- data.frame(as.matrix(distmatrix))
  deco<-j
  dissi<-i
  df2<-rbind(df2, data.frame(deco, dissi, data.frame(distmatrix[1,2:length(distmatrix)])))
}


##CSS method from metagenomeseq. The setup to run metagenomeseq is from MixMC
data.metagenomeSeq <- newMRexperiment(Testdata, featureData=NULL, libSize=NULL, 
                                      normFactors=NULL)  
p <- cumNormStat(data.metagenomeSeq) #default is 0.5
data.cumnorm <- cumNorm(data.metagenomeSeq, p=p)
#CSS data
dataCSS <- MRcounts(data.cumnorm, norm=TRUE, log=TRUE) #A log transformation is also 
#performed as recommended in MixMC 
j <- "CSS"
for (i in c("manhattan", "euclidean", "canberra", "bray", "kulczynski", "jaccard", 
            "gower", "altGower", "horn", "binomial")) {
  distmatrix<-vegdist(t(dataCSS), method=i)
  #Create list containing the dist matrices
  distName <- paste( 'dist', i, j, sep = '' )
  DistList2[[ distName ]]<-distmatrix
  #Make distances into matrix
  distmatrix <- data.frame(as.matrix(distmatrix))
  deco<-j
  dissi<-i
  df2<-rbind(df2, data.frame(deco, dissi, 
                             data.frame(distmatrix[1,2:length(distmatrix)])))
}

## Methods from DESeq2
#Create design formula, not important which column is used in metadata since no DA 
#statistics are obtained, but only used to extract size factors.
#The type="ratio" can not be used since all features have at least one zero instead 
#using the "poscounts". 
design <- formula(paste("~ ", "timepoint.within.group"))
#Create DESeq2 object with matrix and metadata
dds <- DESeqDataSetFromMatrix(countData = Testdata,
                              colData = Metadata,
                              design = design)
dds <- estimateSizeFactors(dds, type="poscounts")
dataDESeq<-sweep(Testdata, MARGIN = 2, sizeFactors(dds), FUN = "/")
j <- "DESeq"
for (i in c("manhattan", "euclidean", "canberra", "bray", "kulczynski", "jaccard", 
            "gower", "altGower", "horn", "binomial")) {
  distmatrix<-vegdist(t(dataDESeq), method=i)
  #Create list containing the dist matrices
  distName <- paste( 'dist', i, j, sep = '' )
  DistList2[[ distName ]]<-distmatrix
  #Make distances into matrix
  distmatrix <- data.frame(as.matrix(distmatrix))
  deco<-j
  dissi<-i
  df2<-rbind(df2, data.frame(deco, dissi, 
                             data.frame(distmatrix[1,2:length(distmatrix)])))
}

##TMM method from edgeR. Both normalizing according to y$samples$lib.size and 
#y$samples$norm.factors 
#DGEList, not important which column is used in metadata since no DA statistics are 
#obtained.
y <- DGEList(counts=Testdata,group=Metadata$Type)
y <- calcNormFactors(y, method="TMM")
dataTMM<-cpm(y)
j <- "TMM"
for (i in c("manhattan", "euclidean", "canberra", "bray", "kulczynski", "jaccard", 
            "gower", "altGower", "horn", "binomial")) {
  distmatrix<-vegdist(t(dataTMM), method=i)
  #Create list containing the dist matrices
  distName <- paste( 'dist', i, j, sep = '' )
  DistList2[[ distName ]]<-distmatrix
  #Make distances into matrix
  distmatrix <- data.frame(as.matrix(distmatrix))
  deco<-j
  dissi<-i
  df2<-rbind(df2, data.frame(deco, dissi, 
                             data.frame(distmatrix[1,2:length(distmatrix)])))
}


###############################Coda framework##################################
##Performing zero estimation before total sum scaling, have some implications in that 
#library size with exact multiplication suddenly is not the same after TSS. 
#clr and ilr
#Zero estimator can not use "rem" because all rows contain a zero 

for (i in c("est","off")) {
  for (j in c("clr", "ilr")) {
    for (k in c("manhattan", "euclidean", "canberra", "gower", "horn")){
      ## Using TaxonomyRaw and doing the TSS after normalization this also means 
      #normalization according to genome size is not implemented. 
      ## Can use different filtering strategies. 1 Bayseian approach estimating zeroes, 
      #2 offset of 1 and removing all rows containing zeroes.          
      #Only minor effects observed 
      # f <- codaSeq.filter(ak_op, min.reads=1000, min.prop=0.005, min.occurrence=0.2, 
      #samples.by.row=FALSE)
      # filtering of the Counttable depending on rowSums. 
      clrdata <- Testdata[rowSums(Testdata)>0,] #Removing all rows that only contains 
      #zeroes
      #For validation make a sample matrix and apply the methods 
      #clrdata <- data.frame(S1=c(1,2,0,2,0,9,0), S2=c(2,4,6,4,12,18,20), 
      #S3=c(2,4,0,4,0,18,0), S4=c(2,4,6,4,0,18,20))
      # Specify method to use
      if (i=="est") {
      # 1. Replace 0 values with an estimate. Be 
        clrdata2 <- t(cmultRepl(t(clrdata), method="CZM", label=0))
      } else if (i=="off") {
      # 2. Offset of 1 if using TSS should find lowest value and maybe divide that 
        #with 10 or other arbitrary offset
        clrdata2 <- clrdata+1
      } else if (i=="rem") {
      # 3. Remove all rows that contain a zero
        row_sub = apply(clrdata, 1, function(row) all(row !=0 ))
        clrdata2<-clrdata[row_sub,]
      } else {
        print("something is wrong")
      }
      
      ## Maks TSS
      #clrdata2<-sweep(clrdata2, 2, colSums(clrdata2), FUN="/")

      if (j=="clr") {
        clrdata2<-clr(t(clrdata2))
      } else if (j=="ilr") {
        clrdata2<-ilr(t(clrdata2))
      } else {
        print("something is wrong")
      }

      distmatrix<-vegdist(clrdata2, method=k) #Could also have run it with the dist 
      #function distmatrix<-data.frame(as.matrix(dist(clrdata2, method="euclidean"))), 
      #but vegdist provides additional dissimilarity indices, but get the same when 
      #using the same index. The indices working in real space that is one of the 
      #advantages doing the the CODA framework and is therefore recommended.   

      #Create list containing the dist matrices
      distName <- paste( 'dist', i, 'total', j, k, sep = '' )
      DistList2[[ distName ]]<-distmatrix
    
      #Make distances into matrix
      distmatrix <- data.frame(as.matrix(distmatrix))
      deco<-paste(i, 'total', j, sep='')
      dissi<-k
      df2<-rbind(df2, data.frame(deco, dissi, 
                                 data.frame(distmatrix[1,2:length(distmatrix)])))
    }
  }
}

##Performing zero estimation after total sum scaling, have some implications in that 
#adding a pseudocount of 1 is not very applicable instead it is estimated as 
#min(apply(Testdata, 1, FUN = function(x) {min(x[x > 0])}))/10. The division with 10 to 
#the lowest number is arbitrary and when working with real data more problematic to set 
#since zeros can be structural or due to inadequate sampling. Performing TSS first means 
#knowledge on sensitivity is lost. 
## Maks TSS
clrdata<-sweep(Testdata, 2, colSums(Testdata), FUN="/")
#clr and ilr
#Zero estimator can not use "rem" because all rows contain a zero 
for (i in c("est","off")) {
  for (j in c("clr", "ilr")) {
    for (k in c("manhattan", "euclidean", "canberra", "gower", "horn")){
      ## Using TaxonomyRaw and doing the TSS after normalization this also means 
      #normalization according to genome size is not implemented. 
      ## Can use different filtering strategies. 1 Bayseian approach estimating zeroes, 
      #2 offset of 1 and removing all rows containing zeroes.    
      #Only minor effects observed 
      # f <- codaSeq.filter(ak_op, min.reads=1000, min.prop=0.005, min.occurrence=0.2, 
      #samples.by.row=FALSE)
      # filtering of the Counttable depending on rowSums. 
      clrdata <- clrdata[rowSums(clrdata)>0,] #Removing all rows that only contains zeroes
      #FOr validation make a sample matrix and apply the methods 
      #clrdata <- data.frame(S1=c(1,2,0,2,0,9,0), S2=c(2,4,6,4,12,18,20), 
      #S3=c(2,4,0,4,0,18,0), S4=c(2,4,6,4,0,18,20))
      # Specify method to use
      if (i=="est") {
        # 1. Replace 0 values with an estimate.
        clrdata2 <- t(cmultRepl(t(clrdata), method="CZM", label=0))
        } else if (i=="off") {
        # 2. Offset of 1 if using TSS should find lowest value and maybe divide that with 
          #10 or other arbitrary offset
        add<-min(apply(clrdata, 1, FUN = function(x) {min(x[x > 0])}))/10
        clrdata2 <- clrdata+add
        } else if (i=="rem") {
        # 3. Remove all rows that contain a zero
        row_sub = apply(clrdata, 1, function(row) all(row !=0 ))
        clrdata2<-clrdata[row_sub,]
        } else {
        print("something is wrong")
      }

      if (j=="clr") {
        clrdata2<-clr(t(clrdata2))
      } else if (j=="ilr") {
        clrdata2<-ilr(t(clrdata2))
      } else {
        print("something is wrong")
      }

      distmatrix<-vegdist(clrdata2, method=k) #Could also have run it with the dist 
      #function distmatrix<-dist(clrdata2, method="euclidean"), but vegdist provides
      #additional dissimilarity indices, but get the same when using the same index.
      #The indices working in real space that is one of the advantages doing the the 
      #CODA framework and is therefore recommended. Does not get meaningful results 
      #when running with for instance "bray", "jaccard" don't know why  

      #Create list containing the dist matrices
      distName <- paste( 'dist', 'total', i, j, k, sep = '' )
      DistList2[[ distName ]]<-distmatrix
    
      #Make distances into matrix
      distmatrix <- data.frame(as.matrix(distmatrix))
      deco<-paste('total', i, j, sep='')
      dissi<-k
      df2<-rbind(df2, data.frame(deco, dissi, 
                                 data.frame(distmatrix[1,2:length(distmatrix)])))
    }
  }
}





###############################Create rank table##################################
df2rank<-bind_cols(df2[,1:2], data.frame(t(apply(df2[,3:length(df2)], 1, rank, 
                                                 ties.method="min"))))

#Save the resuslts as a csv file
#write.table(df2, file="StandNormDistAssessmentTable.txt", sep="\t", dec=",", 
#row.names = F, quote = F)

rm(clrdata, clrdata2, distmatrix, deco, dissi, distName, i, j, zero)
```


### Table relative to ref
```{r}
##Show only selected pipelines
#kable(df)
#kable(dfrank)
#kable(df2)
#kable(df2rank)
```


## Visualizations 
### Heatmaps
```{r}
##Create method column
#df2$Method <- paste(df2$deco, df2$dissi, sep="") 
#row.names(df2)<-df2$Method
#df2Heat<-select(df2, -one_of(c("deco", "dissi", "Method")))

##Had to remove method(s) creating NAs
#df2Heat <- df2Heat[complete.cases(df2Heat),]
##Then I standardized the orgs into zero mean and unit variance
#df2Heat <- data.frame(t(decostand(t(df2Heat), method="max"))) #Can also use scale in 
##pheatmap, but not exactly sure what scaling that is being performed. 
##"max" is used to get comparable indices with the highest dissimilarity being max 
##rowMeans(df2Heat) #Control of standardize worked

##plot<-pheatmap(TaxHeatmap, 
##         margins=c(8,8), 
##         treeheight_row = 100, 
##         treeheight_col = 100, 
##        scale="none", 
##         clustering_distance_cols = distmatrix_Species, 
##         clustering_distance_rows = OrgCluster, 
##         annotation_col = colannodf, 
##         cutree_cols = 2, 
##         show_colnames = FALSE, 
##         cellwidth=5, 
##         cellheight=4, 
##         fontsize=6,
##         annotation_colors = annotation_colorsNew[1:5],
##         annotation_legend = TRUE)
##plot_list[[Subset]] = plot[[4]]

##Select which methods to include in heatmap
##rownames(df2Heat)
#rows<-c("totalmanhattan", "pamanhattan", "hellingermanhattan", "logmanhattan", 
#        "totaleuclidean", "paeuclidean", "hellingereuclidean", "logeuclidean", 
#        "totalbray", "pabray", "hellingerbray", "logbray", "hellingerTSSmanhattan", 
#        "logTSSmanhattan", "hellingerTSSeuclidean", "logTSSeuclidean", "hellingerTSSbray", 
#        "logTSSbray", "Rarmanhattan", "Rareuclidean", "Rarbray", "CSSmanhattan", 
#        "CSSbray", "CSSeuclidean", "DESeqmanhattan", "DESeqbray", "DESeqeuclidean", 
#        "TMMmanhattan", "TMMbray", "TMMeuclidean", "esttotalclreuclidean", 
#        "offtotalclreuclidean", "esttotalilreuclidean", "offtotalilreuclidean", 
#        "totaloffclreuclidean", "totaloffilreuclidean")
#df2Heat2<-df2Heat[grepl(paste(rows, collapse="|"), rownames(df2Heat)),]

##Make dataframe with Metadata for heatmap annotation
#colannodf <- data.frame(Sample=row.names(df2Heat2))
##Create metadata for procrustessumofsquares
#colannodf$Preprocessing <-
#          ifelse(seq(along=(colannodf$Sample)) %in% grep("*clreuc*", colannodf$Sample), 
#                 "clr",
#          ifelse(seq(along=(colannodf$Sample)) %in% grep("*ilreuc*", colannodf$Sample), 
#                 "ilr",        
#          ifelse(seq(along=(colannodf$Sample)) %in% grep("total*", colannodf$Sample), 
#                 "TSS",
#          #ifelse(seq(along=(colannodf$Sample)) %in% grep("max*", colannodf$Sample), 
#          #"max",
#          ifelse(seq(along=(colannodf$Sample)) %in% grep("Rar*", colannodf$Sample), 
#                 "Rar",
#          ifelse(seq(along=(colannodf$Sample)) %in% grep("CSS*", colannodf$Sample), 
#                 "CSS",
#          ifelse(seq(along=(colannodf$Sample)) %in% grep("DESeq*", colannodf$Sample), 
#                 "DESeq",
#          ifelse(seq(along=(colannodf$Sample)) %in% grep("TMM*", colannodf$Sample), 
#                 "TMM",
#          ifelse(seq(along=(colannodf$Sample)) %in% grep("freq*", colannodf$Sample), 
#                 "freq",
#          ifelse(seq(along=(colannodf$Sample)) %in% grep("normalize*", colannodf$Sample), 
#                 "norm",
#          ifelse(seq(along=(colannodf$Sample)) %in% grep("pa*", colannodf$Sample), "pa",
#          ifelse(seq(along=(colannodf$Sample)) %in% grep("hellingerTSS*", 
#                                                         colannodf$Sample), 
#                 "hellingerTSS",
#          ifelse(seq(along=(colannodf$Sample)) %in% grep("hellinger*", colannodf$Sample), 
#                 "hellinger",
#          ifelse(seq(along=(colannodf$Sample)) %in% grep("logTSS*", colannodf$Sample), 
#                 "logTSS",
#          ifelse(seq(along=(colannodf$Sample)) %in% grep("log*", colannodf$Sample), 
#                 "log",
#          ifelse(seq(along=(colannodf$Sample)) %in% grep("chi.square*", colannodf$Sample), 
#                 "chisq",
#            "Other")))))))))))))))#)

#colannodf$betadiversity <-
#          ifelse(seq(along=(colannodf$Sample)) %in% grep("*manhattan", colannodf$Sample), 
#                 "manhattan",
#          ifelse(seq(along=(colannodf$Sample)) %in% grep("*euclidean", colannodf$Sample), 
#                 "euclidean",
#          ifelse(seq(along=(colannodf$Sample)) %in% grep("*canberra", colannodf$Sample), 
#                 "canberra",
#          ifelse(seq(along=(colannodf$Sample)) %in% grep("*bray", colannodf$Sample), 
#                 "bray",
#          ifelse(seq(along=(colannodf$Sample)) %in% grep("*kulczynski", colannodf$Sample), 
#                 "kulczynski",
#          ifelse(seq(along=(colannodf$Sample)) %in% grep("*jaccard", colannodf$Sample), 
#                 "jaccard",
#         ifelse(seq(along=(colannodf$Sample)) %in% grep("*gower", colannodf$Sample), 
#                 "gower",
#          ifelse(seq(along=(colannodf$Sample)) %in% grep("*altGower", colannodf$Sample), 
#                 "altGower",
#          ifelse(seq(along=(colannodf$Sample)) %in% grep("*horn", colannodf$Sample), 
#                 "horn",
#          ifelse(seq(along=(colannodf$Sample)) %in% grep("*binomial", colannodf$Sample), 
#                 "binomial",
#                 "Other"))))))))))

#colannodf<-data.frame(colannodf[,2:3], row.names=colannodf[,1])

##Draw the heatmap
#plotheatmap<-pheatmap(t(df2Heat2),
#          color = colorRampPalette(rev(brewer.pal(n = 7, name = "Blues")))(100),
#          scale="none", 
#          cellwidth=10, 
#          cellheight=8, 
#          annotation_col = colannodf,
#          treeheight_row = 100, 
#          treeheight_col = 100,
#          annotation_colors = annotation_colorsHeat,
#          annotation_legend = TRUE,
#          labels_col = str_replace(rownames(df2Heat2), "bray|manhattan|euclidean", "") 
#          %>% str_replace("est", "est_") 
#          %>% str_replace("off", "off_") 
#          %>% str_replace("clr", "_clr") 
#          %>% str_replace("ilr", "_ilr") 
#          %>% str_replace("TSS", "_TSS") 
#          %>% str_replace("total", "TSS")
#          %>% str_replace("TSSoff__clr", "TSS_off_clr") 
#          %>% str_replace("TSSoff__ilr", "TSS_off_ilr"))

#pdf(paste("heatmapMethods", ".pdf", sep=""), width=9.5, height=6)
#grid.arrange(plotheatmap[[4]])
#dev.off() 
```



### PCoA/PCA DistList
```{r, results="hide", fig.keep="none", fig.show="hide"}
# Create a list to hold the plot objects.
ScreeList <- list()
StressList <- list()
PCoAList <- list()
j<-1 #Can not just use i 

#i<-1
#Can do it both for DistList and DistList2 (DistList2 Only containing exact changes 
#to ref)
for (i in 1:length(DistList2)) { 
#Multi dimensional scaling with capscale 
    i <- DistList2[[j]] 
    PCoAcsObject<-capscale(i~1)
    #PCoAcsObject<-capscale(DistList2[[200]] ~1)
    
    #Creating plot names
    k<-names(DistList2[j])
    j<-j+1

    #Make stressplot
    #Extract ordination distances and merge with observed dissimilarity
    stress<-stressplot(PCoAcsObject)
    df <- melt(as.matrix(stress))
    names(df)<-c("rowOrd", "colOrd", "OrdDist")
    df<-filter(df, OrdDist>0)
    df2 <- melt(as.matrix(i))
    names(df2)<-c("rowObs", "colObs", "ObsDism")
    df2<-filter(df2, ObsDism>0)
    df<-unite(df, mergecol, c(rowOrd, colOrd), remove=FALSE)
    df2<-unite(df2, mergecol, c(rowObs, colObs), remove=FALSE)
    ggstress<-merge(df, df2, by="mergecol")

    #Create plot name
    pltName <- paste( 'stress', k, sep = '' )
    #create stressplot
    StressList[[ pltName ]]<-ggplot(ggstress) + 
      geom_point(aes(ObsDism, OrdDist)) +
      ggtitle(paste("Stressplot", k, sep=" ")) + 
      labs(x = "Observed dissimilarity", y = "Ordination distance") + 
      theme_bw() + 
      theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
            axis.title=element_text(size=12))


    ##Add eig to plot axes. with cmdscale there are negative values not with capscale
    eig <- PCoAcsObject$CA$eig
    # Calculate the variation explained by PCoA1, 2, 3 and 4
    # and use it to generate axis labels
    eig_1_2 <- eig[1:4] / sum(eig) * 100
    eig_1 <- paste("PCoA1", round(eig_1_2[1], digits = 2), "% variance")
    eig_2 <- paste("PCoA2", round(eig_1_2[2], digits = 2), "% variance")
    eig_3 <- paste("PCoA3", round(eig_1_2[3], digits = 2), "% variance")
    eig_4 <- paste("PCoA4", round(eig_1_2[4], digits = 2), "% variance")

    ##Pull out coordinates for plotting from the ca object
    #Structuring to add to Metadata2
    PCoACA<-PCoAcsObject$CA #The ca object contains the actual ordination results: u 
    #((Weighted) orthonormal site scores), v ((Weighted) orthonormal species scores) 
    #all na in mine, 
    #Xbar (The standardized data matrix after previous stages of analysis), 
    #and imaginary.u.eig ???. 
    #Info http://cc.oulu.fi/~jarioksa/softhelp/vegan/html/cca.object.html   
    PCoA<-as.data.frame(PCoACA$u)
    #Change colnames. Now add dis and trans info to names 
    colnames(PCoA) <- c("MDS1","MDS2", "MDS3")
    #Add row names to df
    PCoA$sample <- row.names(PCoA)
    #Merge according to Sample
    Metadata2<-merge(Metadata, PCoA, by="sample")

    #Create plot name
    pltName <- paste( 'PCoA', k, sep = '' )
    #create PCoA
    PCoAList[[ pltName ]]<-ggplot(Metadata2) + 
      #geom_line(aes(x=MDS1, y=MDS2, group=Matching_samples), 
      #size=0.1, linetype="dotted") +  
      geom_jitter(aes(MDS1, MDS2, col=timepoint.within.group, shape=bmi_group), width=0.00, height=0.00, 
                  alpha=0.8, size=3, stroke=1.5) +
      #geom_point(aes(MDS1, MDS2, color = Sample_LPSX, group = Sample, 
      #shape = Temperature), size=5) +
      scale_color_manual(values=TestCol) +  
      scale_shape_manual(values=LevelShape) +
      ggtitle(paste("PCA/PCoA ", k)) + 
      #labs(colour="Temperature (?C)", shape="Processing", x = eig_1, y = eig_2) + 
      theme_bw() + 
      theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
            axis.title=element_text(size=12), legend.position="nothing") #+ 
      #scale_y_reverse() #If you want the y scale reversed, to make plots easier to 
      #compare
      #scale_x_reverse() #If you want the x scale reversed, to make plots easier to 
      #compare
    #ggsave(paste("CapscalePCoAYoungCOMPARE", "Genus", i, OrgFlt, ".pdf", sep=""), 
    #height=6, width=12)
    #ggtitle(paste("PCoA ", i, " n orgs > 1% = ", nrow(Tax2))) #Used with filtering

    #Screeplot 
    screeplot<-data.frame(PCoAcsObject$CA$eig)
    colnames(screeplot)<-c("eig")
    screeplot$eig <- screeplot$eig[1:length(screeplot$eig)] / sum(screeplot$eig) * 100
    screeplot<-add_rownames(screeplot, "MDS")
    screeplot$MDS <- factor(screeplot$MDS, 
                            levels=c(sprintf("MDS%d", 1:length(screeplot$eig))))

    #Create plot name
    pltName <- paste( 'scree', k, sep = '' )
    #create screeplot
    ScreeList[[ pltName ]]<-ggplot(screeplot, aes(x=MDS, y=eig)) + 
      geom_bar(stat="identity") + 
      labs(x ="MDS", y ="eig (%)") + 
      ggtitle(paste("Screeplot ", k)) +
      theme_bw() +
      theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
            axis.title=element_text(size=12), axis.text.x=element_blank(), 
            axis.ticks.x=element_blank()) 
    #ggsave(filename=paste("ScreeplotCapscalePCoA", "Genus", i, OrgFlt, ".pdf", sep=""), 
    #height=6, width=12)
    
}

############################################################

## Make PCA and PCoA
lay <- rbind(c(1,2,3,4,5),
             c(6,7,8,9,10),
             c(11,12,13,14,15),
             c(16,17,18,19,20),
             c(21,22,23,24,25),
             c(26,27,28,29,30),
             c(31,32,33,34,35),
             c(36,NA,NA,NA,NA))
#Make pdf
pdf(paste("PCoAorPCA", "Pipelines", ".pdf", sep=""), width=24, height=24)
grid.arrange(PCoAList$PCoAdistmanhattantotal, PCoAList$PCoAdistmanhattanpa , 
             PCoAList$PCoAdistmanhattanhellinger, PCoAList$PCoAdistmanhattanlog, 
             PCoAList$PCoAdisteuclideantotal, PCoAList$PCoAdisteuclideanpa,
             PCoAList$PCoAdisteuclideanhellinger, PCoAList$PCoAdisteuclideanlog, 
             PCoAList$PCoAdistbraytotal, PCoAList$PCoAdistbraypa, 
             PCoAList$PCoAdistbrayhellinger, PCoAList$PCoAdistbraylog,
             PCoAList$PCoAdistmanhattantotalhellinger, 
             PCoAList$PCoAdistmanhattantotallog,
             PCoAList$PCoAdisteuclideantotalhellinger, 
             PCoAList$PCoAdisteuclideantotallog,
             PCoAList$PCoAdistbraytotalhellinger, PCoAList$PCoAdistbraytotallog, 
             PCoAList$PCoAdistmanhattanRar, PCoAList$PCoAdisteuclideanRar, 
             PCoAList$PCoAdistbrayRar, PCoAList$PCoAdistmanhattanCSS, 
             PCoAList$PCoAdistbrayCSS, PCoAList$PCoAdisteuclideanCSS, 
             PCoAList$PCoAdistmanhattanDESeq, PCoAList$PCoAdistbrayDESeq, 
             PCoAList$PCoAdisteuclideanDESeq, PCoAList$PCoAdistmanhattanTMM, 
             PCoAList$PCoAdistbrayTMM, PCoAList$PCoAdisteuclideanTMM, 
             PCoAList$PCoAdistesttotalclreuclidean, 
             PCoAList$PCoAdistofftotalclreuclidean, 
             PCoAList$PCoAdistesttotalilreuclidean, 
             PCoAList$PCoAdistofftotalilreuclidean, 
             PCoAList$PCoAdisttotaloffclreuclidean, 
             PCoAList$PCoAdisttotaloffilreuclidean, layout_matrix = lay)
dev.off()

#Extract legend
legend<-ggplot(Metadata2) + 
      #geom_line(aes(x=MDS1, y=MDS2, group=Matching_samples), size=0.1, 
      #linetype="dotted") +  
      geom_jitter(aes(MDS1, MDS2, col=timepoint.within.group, shape=bmi_group), width=0.00, height=0.00, 
                  alpha=0.8, size=3, stroke=1.5) +
      #geom_point(aes(MDS1, MDS2, color = Sample_LPSX, group = Sample, 
      #shape = Temperature), size=5) +
      scale_color_manual(values=TestCol) +  
      scale_shape_manual(values=LevelShape) +
      ggtitle(paste("PCA/PCoA ", k)) + 
      #labs(colour="Temperature (?C)", shape="Processing", x = eig_1, y = eig_2) + 
      theme_bw() + 
      theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
            axis.title=element_text(size=12), legend.position="bottom")
legendplot<-get_legend(legend)
pdf(paste("LegendPCoA", ".pdf", sep=""), width=36, height=12)
grid.arrange(legendplot)
dev.off()
```





### Procrustes analysis visualized as PCoA
Make protest of all pairwise comparisons and sum of squares store in dist object (proCpairAllmethods)
```{r}
#Selected methods for creating pairwise procrustes correlations/sumofsquares/etc.
DistList2Sel<-DistList2[c("distmanhattantotal", "distmanhattanpa" , 
                          "distmanhattanhellinger", "distmanhattanlog", 
                          "disteuclideantotal", "disteuclideanpa", 
                          "disteuclideanhellinger", "disteuclideanlog", 
                          "distbraytotal", "distbraypa", "distbrayhellinger", 
                          "distbraylog", "distmanhattantotalhellinger", 
                          "distmanhattantotallog", "disteuclideantotalhellinger", 
                          "disteuclideantotallog", "distbraytotalhellinger", 
                          "distbraytotallog", "distmanhattanRar", "disteuclideanRar",
                          "distbrayRar", "distmanhattanCSS", "distbrayCSS", 
                          "disteuclideanCSS", "distmanhattanDESeq", "distbrayDESeq", 
                          "disteuclideanDESeq", "distmanhattanTMM", "distbrayTMM", 
                          "disteuclideanTMM", "distesttotalclreuclidean", 
                          "distofftotalclreuclidean", "distesttotalilreuclidean", 
                          "distofftotalilreuclidean", "disttotaloffclreuclidean", 
                          "disttotaloffilreuclidean")]
#DistList2Sel<-DistList2[c("distmanhattantotal", "distmanhattanpa" , 
#"distmanhattanhellinger", "distmanhattanlog", "disteuclideantotal", 
#"disteuclideanpa", "disteuclideanhellinger", "disteuclideanlog", "distbraytotal", 
#"distbraypa", "distbrayhellinger", "distbraylog", "distmanhattantotalhellinger", 
#"distmanhattantotallog", "disteuclideantotalhellinger", "disteuclideantotallog", 
#"distbraytotalhellinger", "distbraytotallog", "distmanhattanRar", "disteuclideanRar", 
#"distbrayRar", "distbrayCSS", "disteuclideanCSS", "distmanhattanDESeq", 
#"distbrayDESeq", "disteuclideanDESeq", "distmanhattanTMM", "distbrayTMM", 
#"disteuclideanTMM", "distesttotalclreuclidean", "distofftotalclreuclidean", 
#"distesttotalilreuclidean", "disttotaloffclreuclidean")] 
##To varify I obtained the same results from ilr and clr
#DistList2Sel<-DistList2 #To select all
                          
k<-1
l<-1
#Create dataframe to hold the correlations
proCpairAllmethods<-setNames(data.frame(matrix(ncol=length(DistList2Sel), 
                                               nrow=length(DistList2Sel))), 
                             c(names(DistList2Sel)))
rownames(proCpairAllmethods)<-c(names(DistList2Sel))
proCpairAllmethodsCor<-proCpairAllmethods
proCpairAllmethodsSS<-proCpairAllmethods
#proCpairAllmethodsCorVec<-numeric()
#proCpairAllmethodsSSVec<-numeric()

#Can do it both for DistList and DistList2 (Only containing exact changes to ref) 
#To test can print the 3 lines below and change length(DistList2) to a smaller value
for (i in 1:length(DistList2Sel)) { 
  for (j in 1:length(DistList2Sel)) {  
    j <- DistList2Sel[[k]]
    #print(names(DistList2Sel[k]))
    i <- DistList2Sel[[l]] 
    #print(names(DistList2Sel[l]))
    
    #Make protest
    prot<-protest(capscale(i~1), capscale(j~1))
    #prot
    #summary(prot)
    #plot(prot)
    #plot(prot, kind=2)
    #Correlations
    #print(prot$t0)
    proCpairAllmethods[k,l]<-(1-prot$t0) #Can try with different measuers correlations 
    #(prot$t0), sum of squares (prot$ss). PCoA/PCA title have to be changed accordingly 
    #below. Changed this to always being correlations, but other metrics could be 
    #provided. 
    #proCpairAllmethodsCorVec<-c(proCpairAllmethodsCorVec, prot$t0) #Vector of raw 
    #correlations
    #proCpairAllmethodsSSVec<-c(proCpairAllmethodsCorVec, prot$ss) #Vector of raw 
    #sum of squares
    proCpairAllmethodsCor[k,l]<-(prot$t0) #Dist raw correlations
    proCpairAllmethodsSS[k,l]<-(prot$ss) #Have made a seperate object to store sum of 
    #squares 
    k <- k+1 
  }
  #Reasign 1 to k and iterate l
  #print((l/length(DistList2Sel))*100) #Time in percentage computed
  l <- l+1
  k <- 1
}

#See if a df works with capscale or have to change into class dist and create PCoA
proCpairAllmethods<-as.dist(proCpairAllmethods) #I'm getting the right number of 
#observations corresponding to the lower diagonal the as.dist function default is 
#diag=FALSE, upper=FALSE, auto_convert_data_frames=TRUE.
proCpairAllmethodsCor<-as.dist(proCpairAllmethodsCor)
proCpairAllmethodsSS<-as.dist(proCpairAllmethodsSS)

##Save the resuslts as a csv file
#write.table(data.frame(matrix(proCpairAllmethods)), 
#            file="ProcrustesComparingMethodsCor.txt", sep="\t", dec=",", row.names = F, 
#            quote = F)
#write.table(data.frame(matrix(proCpairAllmethodsSS)), 
#            file="ProcrustesComparingMethodsSS.txt", sep="\t", dec=",", row.names = F, 
#            quote = F)
```





### Create PCoA of pairwise procrustes correlations and sum of squares. 
Additional validation plots are provided in the form of stress plots, scree plots and density plots
```{r fig.show="hide"}
#proCpairAllmethods
#proCpairAllmethodsSS
#proCpairAllmethodsCorVec

##Store PCoAs, stessplots and screeplots in the already created lists
#Create capscale object for both correlations and sum of squares
PCoAcsObject<-capscale(proCpairAllmethods~1)
PCoAcsObjectSS<-capscale(proCpairAllmethodsSS~1)
    
#Make stressplot
#Extract ordination distances and merge with observed dissimilarity
#Correlations
stress<-stressplot(PCoAcsObject)
df <- melt(as.matrix(stress))
names(df)<-c("rowOrd", "colOrd", "OrdDist")
df<-filter(df, OrdDist>0)
df2 <- melt(as.matrix(proCpairAllmethods))
names(df2)<-c("rowObs", "colObs", "ObsDism")
df2<-filter(df2, ObsDism>0)
df<-unite(df, mergecol, c(rowOrd, colOrd), remove=FALSE)
df2<-unite(df2, mergecol, c(rowObs, colObs), remove=FALSE)
ggstress<-merge(df, df2, by="mergecol")
#Create plot name correlations
pltName <- paste( 'stress', 'procrustesCor', sep = '' )
#create stressplot correlations
StressList[[ pltName ]]<-ggplot(ggstress) + 
  geom_point(aes(ObsDism, OrdDist), size=1) + #Can change to 0.01 when running all
  ggtitle(paste("Stress plot", sep=" ")) + 
  labs(x = "Observed dissimilarity", y = "Ordination distance") + 
  theme_bw() + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        axis.title=element_text(size=12))

#Sum of squares
stressSS<-stressplot(PCoAcsObjectSS)
dfSS <- melt(as.matrix(stressSS))
names(dfSS)<-c("rowOrd", "colOrd", "OrdDist")
dfSS<-filter(dfSS, OrdDist>0)
df2SS <- melt(as.matrix(proCpairAllmethodsSS))
names(df2SS)<-c("rowObs", "colObs", "ObsDism")
df2SS<-filter(df2SS, ObsDism>0)
dfSS<-unite(dfSS, mergecol, c(rowOrd, colOrd), remove=FALSE)
df2SS<-unite(df2SS, mergecol, c(rowObs, colObs), remove=FALSE)
ggstressSS<-merge(dfSS, df2SS, by="mergecol")
#Create plot name sum of squares
pltName <- paste( 'stress', 'procrustesSS', sep = '' )
#create stressplot sum of squares
StressList[[ pltName ]]<-ggplot(ggstressSS) + 
  geom_point(aes(ObsDism, OrdDist), size=1) + #Can change to 0.01 when running all
  ggtitle(paste("Stress plot", sep=" ")) + 
  labs(x = "Observed dissimilarity", y = "Ordination distance") + 
  theme_bw() + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        axis.title=element_text(size=12))


##PCoA correlations
##Add eig to plot axes. with cmdscale there are negative values not with capscale
eig <- PCoAcsObject$CA$eig
# Calculate the variation explained by PCoA1, 2, 3 and 4
# and use it to generate axis labels
eig_1_2 <- eig[1:4] / sum(eig) * 100
eig_1 <- paste("PCoA1", round(eig_1_2[1], digits = 2), "% variance")
eig_2 <- paste("PCoA2", round(eig_1_2[2], digits = 2), "% variance")
eig_3 <- paste("PCoA3", round(eig_1_2[3], digits = 2), "% variance")
eig_4 <- paste("PCoA4", round(eig_1_2[4], digits = 2), "% variance")
##Pull out coordinates for plotting from the ca object
#Structuring to add to Metadata2
PCoACA<-PCoAcsObject$CA #The ca object contains the actual ordination results: 
#u ((Weighted) orthonormal site scores), v ((Weighted) orthonormal species scores) 
#all na in mine, Xbar (The standardized data matrix after previous stages of analysis), 
#and imaginary.u.eig ???. 
#Info http://cc.oulu.fi/~jarioksa/softhelp/vegan/html/cca.object.html   
PCoA<-as.data.frame(PCoACA$u)
#Change colnames. Now add dis and trans info to names 
colnames(PCoA) <- c("MDS1","MDS2", "MDS3","MDS4")
#Add row names to df
PCoA$Sample <- row.names(PCoA)

#Create metadata 
MetadataProC<-data.frame(Sample=rownames(PCoA))
MetadataProC$Trans <-
          ifelse(seq(along=(MetadataProC$Sample)) %in% grep("*totallog", 
                                                            MetadataProC$Sample), 
                 "TSS_log",
          ifelse(seq(along=(MetadataProC$Sample)) %in% grep("*totalhellinger", 
                                                            MetadataProC$Sample), 
                 "TSS_hellinger",
          ifelse(seq(along=(MetadataProC$Sample)) %in% grep("*clr", MetadataProC$Sample), 
                 "clr",
          ifelse(seq(along=(MetadataProC$Sample)) %in% grep("*ilr", MetadataProC$Sample), 
                 "ilr",        
          ifelse(seq(along=(MetadataProC$Sample)) %in% grep("*total", 
                                                            MetadataProC$Sample), 
                 "TSS",
          ifelse(seq(along=(MetadataProC$Sample)) %in% grep("*max", MetadataProC$Sample), 
                 "max",
          ifelse(seq(along=(MetadataProC$Sample)) %in% grep("*freq", MetadataProC$Sample), 
                 "freq",
          ifelse(seq(along=(MetadataProC$Sample)) %in% grep("*normalize", 
                                                            MetadataProC$Sample), 
                 "norm",
          ifelse(seq(along=(MetadataProC$Sample)) %in% grep("*pa", MetadataProC$Sample), 
                 "pa",
          ifelse(seq(along=(MetadataProC$Sample)) %in% grep("*hellinger", 
                                                            MetadataProC$Sample),
                 "hellinger",
          ifelse(seq(along=(MetadataProC$Sample)) %in% grep("*log", MetadataProC$Sample), 
                 "log",
          ifelse(seq(along=(MetadataProC$Sample)) %in% grep("*chi.square", 
                                                            MetadataProC$Sample), 
                 "chisq",
          ifelse(seq(along=(MetadataProC$Sample)) %in% grep("*CSS", MetadataProC$Sample), 
                 "CSS",
          ifelse(seq(along=(MetadataProC$Sample)) %in% grep("*TMM", MetadataProC$Sample), 
                 "TMM",
          ifelse(seq(along=(MetadataProC$Sample)) %in% grep("*DESeq", 
                                                            MetadataProC$Sample), 
                 "DESeq",
          ifelse(seq(along=(MetadataProC$Sample)) %in% grep("*Rar", MetadataProC$Sample), 
                 "Rarefy",
                 "Other"))))))))))))))))

MetadataProC$Dist <-
          ifelse(seq(along=(MetadataProC$Sample)) %in% grep("*manhattan*", 
                                                            MetadataProC$Sample), 
                 "manhattan",
          ifelse(seq(along=(MetadataProC$Sample)) %in% grep("*euclidean*",
                                                            MetadataProC$Sample),
                 "euclidean",
          ifelse(seq(along=(MetadataProC$Sample)) %in% grep("*canberra*", 
                                                            MetadataProC$Sample),
                 "canberra",
          ifelse(seq(along=(MetadataProC$Sample)) %in% grep("*bray*", 
                                                            MetadataProC$Sample), 
                 "bray",
          ifelse(seq(along=(MetadataProC$Sample)) %in% grep("*kulczynski*", 
                                                            MetadataProC$Sample), 
                 "kulczynski",
          ifelse(seq(along=(MetadataProC$Sample)) %in% grep("*jaccard*", 
                                                            MetadataProC$Sample), 
                 "jaccard",
          ifelse(seq(along=(MetadataProC$Sample)) %in% grep("*gower*", 
                                                            MetadataProC$Sample), 
                 "gower",
          ifelse(seq(along=(MetadataProC$Sample)) %in% grep("*altGower*",
                                                            MetadataProC$Sample), 
                 "altGower",
          ifelse(seq(along=(MetadataProC$Sample)) %in% grep("*horn*", 
                                                            MetadataProC$Sample), 
                 "horn",
          ifelse(seq(along=(MetadataProC$Sample)) %in% grep("*binomial*", 
                                                            MetadataProC$Sample), 
                 "binomial",
          ifelse(seq(along=(MetadataProC$Sample)) %in% grep("*clr", 
                                                            MetadataProC$Sample), 
                 "euclidean",
                 "Other")))))))))))

#Merge according to Sample
MetadataProC2<-merge(MetadataProC, PCoA, by="Sample")

#Create plot name
pltName <- paste( 'PCoA', 'procrustesCor', sep = '' )
#create PCoA
PCoAList[[ pltName ]]<-ggplot(MetadataProC2) + 
  #geom_line(aes(x=MDS1, y=MDS2, group=Matching_samples), size=0.1, 
  #linetype="dotted") +  
  geom_jitter(aes(MDS1, MDS2, col=Trans, shape=Dist), width=0.00, height=0.00, alpha=0.8, 
              size=3, stroke=1.5) +
  #geom_point(aes(MDS1, MDS2, color = Sample_LPSX, group = Sample, shape = Temperature), 
  #size=5) +
  scale_color_manual(values=ProCCol) +  
  scale_shape_manual(values=ProCShape) +
  ggtitle(paste("PCoA ", 'procrustes rotation 1-correlations')) + 
  labs(colour="Preprocessing", shape="?diversity", x = eig_1, y = eig_2) + 
  theme_bw() + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        axis.title=element_text(size=12), legend.position="bottom") #+
  #stat_ellipse(data=filter(MetadataProC2[,1:6], grepl("clr|ilr", Trans)), 
  #aes(MDS1, MDS2), level=0.80)
  #scale_y_reverse() #If you want the y scale reversed, to make plots easier to compare
  #scale_x_reverse() #If you want the x scale reversed, to make plots easier to compare
#ggsave(paste("CapscalePCoAYoungCOMPARE", "Genus", i, OrgFlt, ".pdf", sep=""), height=6, 
#width=12)
#ggtitle(paste("PCoA ", i, " n orgs > 1% = ", nrow(Tax2))) #Used with filtering

#Making interactive plot with plotly
ggplotly(ggplot(MetadataProC2[,1:7]) + 
  geom_jitter(aes(MDS1, MDS2, col=Trans, shape=Dist, group=Sample), width=0.00, 
              height=0.00, alpha=0.8, size=3, stroke=1.5) +
  scale_color_manual(values=ProCCol) +  
  scale_shape_manual(values=ProCShape) +
  ggtitle(paste("PCoA ", 'procrustes rotation 1-correlations')) + 
  labs(colour="Transformation", shape="Distance", x = eig_1, y = eig_2) + 
  theme_bw() + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        axis.title=element_text(size=12), legend.position="bottom"))

##PCoA sum of squares overwriting the objects created above for correlations using the 
#already created metadata
##Add eig to plot axes. with cmdscale there are negative values not with capscale
eig <- PCoAcsObjectSS$CA$eig
# Calculate the variation explained by PCoA1, 2, 3 and 4
# and use it to generate axis labels
eig_1_2 <- eig[1:4] / sum(eig) * 100
eig_1 <- paste("PCoA1", round(eig_1_2[1], digits = 2), "% variance")
eig_2 <- paste("PCoA2", round(eig_1_2[2], digits = 2), "% variance")
eig_3 <- paste("PCoA3", round(eig_1_2[3], digits = 2), "% variance")
eig_4 <- paste("PCoA4", round(eig_1_2[4], digits = 2), "% variance")
##Pull out coordinates for plotting from the ca object
#Structuring to add to Metadata2
PCoACA<-PCoAcsObjectSS$CA #The ca object contains the actual ordination results: u 
#((Weighted) orthonormal site scores), v ((Weighted) orthonormal species scores) all 
#na in mine, Xbar (The standardized data matrix after previous stages of analysis), 
#and imaginary.u.eig ???. 
#Info http://cc.oulu.fi/~jarioksa/softhelp/vegan/html/cca.object.html   
PCoA<-as.data.frame(PCoACA$u)
#Change colnames. Now add dis and trans info to names 
colnames(PCoA) <- c("MDS1","MDS2", "MDS3","MDS4")
#Add row names to df
PCoA$Sample <- row.names(PCoA)

#Merge according to Sample
MetadataProC2<-merge(MetadataProC, PCoA, by="Sample")

#Create plot name
pltName <- paste( 'PCoA', 'procrustesSS', sep = '' )
#create PCoA
PCoAList[[ pltName ]]<-ggplot(MetadataProC2) + 
  #geom_line(aes(x=MDS1, y=MDS2, group=Matching_samples), size=0.1, linetype="dotted") +  
  geom_jitter(aes(MDS1, MDS2, col=Trans, shape=Dist), width=0.00, height=0.00, alpha=0.8, 
              size=3, stroke=1.5) +
  #geom_point(aes(MDS1, MDS2, color = Sample_LPSX, group = Sample, shape = Temperature), 
  #size=5) +
  scale_color_manual(values=ProCCol) +  
  scale_shape_manual(values=ProCShape) +
  ggtitle(paste("PCoA ", 'procrustes rotation sum of squares')) + 
  labs(colour="Transformation", shape="Distance", x = eig_1, y = eig_2) + 
  theme_bw() + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        axis.title=element_text(size=12), legend.position="bottom") #+ 
  #scale_y_reverse() #If you want the y scale reversed, to make plots easier to compare
  #scale_x_reverse() #If you want the x scale reversed, to make plots easier to compare
#ggsave(paste("CapscalePCoAYoungCOMPARE", "Genus", i, OrgFlt, ".pdf", sep=""), height=6, 
#width=12)
#ggtitle(paste("PCoA ", i, " n orgs > 1% = ", nrow(Tax2))) #Used with filtering



#Screeplot correlations 
screeplot<-data.frame(PCoAcsObject$CA$eig)
colnames(screeplot)<-c("eig")
screeplot$eig <- screeplot$eig[1:length(screeplot$eig)] / sum(screeplot$eig) * 100
screeplot<-add_rownames(screeplot, "MDS")
screeplot$MDS <- factor(screeplot$MDS, 
                        levels=c(sprintf("MDS%d", 1:length(screeplot$eig))))
#Create plot name
pltName <- paste( 'scree', 'procrustesCor', sep = '' )
#create screeplot
ScreeList[[ pltName ]]<-ggplot(screeplot, aes(x=MDS, y=eig)) + 
  geom_bar(stat="identity") + 
  labs(x ="MDS", y ="eig (%)") + 
  ggtitle(paste("Scree plot ")) +
  theme_bw() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        axis.title=element_text(size=12), axis.text.x=element_blank(), 
        axis.ticks.x=element_blank()) 
#ggsave(filename=paste("ScreeplotCapscalePCoA", "Genus", i, OrgFlt, ".pdf", sep=""), 
#height=6, width=12)


#Screeplot sum of squares 
screeplot<-data.frame(PCoAcsObjectSS$CA$eig)
colnames(screeplot)<-c("eig")
screeplot$eig <- screeplot$eig[1:length(screeplot$eig)] / sum(screeplot$eig) * 100
screeplot<-add_rownames(screeplot, "MDS")
screeplot$MDS <- factor(screeplot$MDS, 
                        levels=c(sprintf("MDS%d", 1:length(screeplot$eig))))
#Create plot name
pltName <- paste( 'scree', 'procrustesSS', sep = '' )
#create screeplot
ScreeList[[ pltName ]]<-ggplot(screeplot, aes(x=MDS, y=eig)) + 
  geom_bar(stat="identity") + 
  labs(x ="MDS", y ="eig (%)") + 
  ggtitle(paste("Scree plot ")) +
  theme_bw() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.title=element_text(size=12), axis.text.x=element_blank(), 
        axis.ticks.x=element_blank()) 
#ggsave(filename=paste("ScreeplotCapscalePCoA", "Genus", i, OrgFlt, ".pdf", sep=""), 
#height=6, width=12)


#Create histogram and density plot for correlations and sum of squres. Sensitivity 
#analysis 
#The histogram and density plot is to be used as an assessment of further 
#investigations are needed in order to decide on how to process metagenomics data. 
Correls<-melt_dist(matrix(proCpairAllmethodsCor))
PCoAList$densityplotCor<-ggplot(Correls, aes(x=dist)) + 
  geom_histogram(aes(y=..density..), binwidth=0.01, colour="black", fill="white") + 
  #..density.. is to have it scale with geom_density
  geom_density(alpha=.25, fill="#FF6666") + 
  labs(x ="Correlation", y ="Density") + 
  ggtitle(paste("Density plot ")) +
  xlim(0,1) +
  theme_bw() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        axis.title=element_text(size=12)) 

Sumssqs<-melt_dist(matrix(proCpairAllmethodsSS))
PCoAList$densityplotSS<-ggplot(Sumssqs, aes(x=dist)) + 
  geom_histogram(aes(y=..density..), binwidth=0.01, colour="black", fill="white") + 
  #..density.. is to have it scale with geom_density
  geom_density(alpha=.25, fill="#FF6666") + 
  labs(x ="Sum of squares", y ="Density") + 
  ggtitle(paste("Density plot ")) +
  xlim(0,1) +
  theme_bw() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        axis.title=element_text(size=12)) 


###################################################

#Have the plots stored in lists
lay <- rbind(c(1,1),
             c(1,1),
             c(2,3))

## Create figure with correlations
pdf(paste("PCoAprocrustesrotationcorrelations", ".pdf", sep=""), width=12.5, height=10)
grid.arrange(PCoAList$PCoAprocrustesCor, StressList$stressprocrustesCor, 
             ScreeList$screeprocrustesCor, layout_matrix = lay)
dev.off()

## Create figure with sum of squares
pdf(paste("PCoAprocrustesrotationsumofsquares", ".pdf", sep=""), width=12.5, height=10)
grid.arrange(PCoAList$PCoAprocrustesSS, StressList$stressprocrustesSS, 
             ScreeList$screeprocrustesSS, layout_matrix = lay)
dev.off()

#Have the plots stored in lists
lay <- rbind(c(1,1,1,1),
             c(1,1,1,1),
             c(2,2,3,4))

## Create figure with correlations
pdf(paste("PCoAprocrustesrotationcorrelationsDensity", ".pdf", sep=""), width=12.5, 
    height=10)
grid.arrange(PCoAList$PCoAprocrustesCor, PCoAList$densityplotCor, 
             StressList$stressprocrustesCor, ScreeList$screeprocrustesCor, 
             layout_matrix = lay)
dev.off()

## Create figure with sum of squares
pdf(paste("PCoAprocrustesrotationsumofsquaresDensity", ".pdf", sep=""), width=12.5, 
    height=10)
grid.arrange(PCoAList$PCoAprocrustesSS, PCoAList$densityplotSS, 
             StressList$stressprocrustesSS, ScreeList$screeprocrustesSS, 
             layout_matrix = lay)
dev.off()
```


## Additional
### Session information
```{r sesson_info}
sessionInfo()
```

### This document was processed on: 
```{r}
Sys.Date()
```





